---
title: "machine learning assignment"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Start by downloading and loading the data

```{r download and load data}
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-training.csv", "/Users/mitchelltaylor/coursera/assignments/machine_learning/pml-training.csv")
download.file("https://d396qusza40orc.cloudfront.net/predmachlearn/pml-testing.csv", "/Users/mitchelltaylor/coursera/assignments/machine_learning/pml-testing.csv")
train <- read.csv("/Users/mitchelltaylor/coursera/assignments/machine_learning/pml-training.csv")
test <- read.csv("/Users/mitchelltaylor/coursera/assignments/machine_learning/pml-testing.csv")
```

Remove non predictive variables and find eligible variables on test data (ie. remove variables with all NA's or same level as not useful for prediction).
```{r}
# drop non predictive variables
nonpred_vars <- c("X", "user_name", "raw_timestamp_part_1", "raw_timestamp_part_2", "cvtd_timestamp", "new_window", "num_window")
train_clean <- train[, !(names(train) %in% nonpred_vars)]
test_clean <- test[, !(names(test) %in% nonpred_vars)]

# drop all the missing variables (on test)
allNA <- sapply(test_clean, function(x) all(is.na(x)))
train_clean <- train_clean[, !allNA]
test_clean <- test_clean[, !allNA]

# partition train data
library(caret)
set.seed(1234)
inTrain <- createDataPartition(y=train_clean$classe,
                              p=0.7, list=FALSE)
train_mod <- train_clean[inTrain,]
test_mod <- train_clean[-inTrain,]
```

Do some EDA...
```{r}


```

Decision Tree
```{r}
# Fit simple decision tree with defaults
dec_tree <- train(classe ~ ., method="rpart", data=train_mod)

# Look at results
dec_tree$finalModel

plot(dec_tree$finalModel, uniform=TRUE, 
      main="Classification Tree")
text(dec_tree$finalModel, use.n=TRUE, all=TRUE, cex=.8)

# Score model on train and test
train_mod$dec_tree_pred <- predict(dec_tree, train_mod)
test_mod$dec_tree_pred <- predict(dec_tree, test_mod)

# get accuracy
confusionMatrix(train_mod$dec_tree_pred, train_mod$classe)[[3]][1]
confusionMatrix(test_mod$dec_tree_pred, test_mod$classe)[[3]][1]

#library(rattle)
#fancyRpartPlot(dec_tree$finalModel)
```

GBM
```{r}
# Fit gbm with defaults
control_gbm <- trainControl(method = "cv", number = 5)
gbm <- train(classe ~ . - dec_tree_pred, data=train_mod, method = "gbm", 
             trControl = control_gbm, verbose = FALSE)

# Look at results
gbm$finalModel

# Score model on train and test
train_mod$gbm_pred <- predict(gbm, train_mod)
test_mod$gbm_pred <- predict(gbm, test_mod)

# get accuracy
confusionMatrix(train_mod$gbm_pred, train_mod$classe)[[3]][1]
confusionMatrix(test_mod$gbm_pred, test_mod$classe)[[3]][1]
```

Random Forest
```{r}
# Fit gbm with defaults
control_rf <- trainControl(method="cv", number=5)
rf <- train(classe ~ . - dec_tree_pred - gbm_pred, method="rf",
            data=train_mod, trControl=control_rf)

# Look at results
rf$finalModel

# Score model on train and test
train_mod$rf_pred <- predict(rf, train_mod)
test_mod$rf_pred <- predict(rf, test_mod)

# get accuracy
confusionMatrix(train_mod$rf_pred, train_mod$classe)[[3]][1]
confusionMatrix(test_mod$rf_pred, test_mod$classe)[[3]][1]
```

Apply to 20 row test data
```{r}
test_clean$dec_tree_pred <- predict(dec_tree, test_clean)
test_clean$gbm_pred <- predict(gbm, test_clean)
prediction_quiz <- predict(rf, test_clean)
```

## Including Plots

You can also embed plots, for example:

```{r pressure, echo=FALSE}
plot(pressure)
```
